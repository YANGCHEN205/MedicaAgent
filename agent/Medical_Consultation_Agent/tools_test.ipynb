{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mca_tools import tools_map, query_user_for_details,gen_tools_desc\n",
    "from mca_prompt import gen_prompt, user_prompt\n",
    "tools_dict= gen_tools_desc()\n",
    "print(tools_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mca_tools import tools_map, query_user_for_details\n",
    "from mca_prompt import gen_prompt, user_prompt\n",
    "from mca_model_provider import ModelProvider\n",
    "from dotenv import load_dotenv\n",
    "import dashscope\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "mp = ModelProvider()\n",
    "\n",
    "dashscope.api_key = \"sk-f529539e3a50472fac783cf1e99fddef\"\n",
    "os.environ[\"TAVILY_API_KEY\"] = \"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\"\n",
    "\n",
    "def parse_thoughts(response, cur_request_time,max_request_time,debug):\n",
    "    \"\"\"解析模型返回的响应，提取关键信息并格式化为字符串，并根据debug参数决定是否打印\"\"\"\n",
    "    try:\n",
    "        thoughts = response.get(\"thoughts\")\n",
    "        planning = thoughts.get(\"planning\")\n",
    "        reasoning = thoughts.get(\"reasoning\")\n",
    "        reflection = thoughts.get(\"reflection\")\n",
    "        summary = thoughts.get(\"summary\")\n",
    "        observation = response.get(\"observation\")\n",
    "        prompt = f\"planning: {planning}\\nreasoning: {reasoning}\\nreflection: {reflection}\\nobservation: {observation}\\nsummary: {summary}\"\n",
    "        prompt += f\"\\n这是医疗知识库第{cur_request_time}次响应，最多执行{max_request_time}次\\n\" \n",
    "        # if debug:\n",
    "        #     print(prompt)\n",
    "        return prompt\n",
    "    except Exception as e:\n",
    "        print(f\"parse_thoughts error: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def execute_action(action_name, action_args, debug):\n",
    "    \"\"\"根据动作名称执行相应的工具函数，并根据debug参数决定是否打印动作信息\"\"\"\n",
    "    try:\n",
    "        func = tools_map.get(action_name)\n",
    "        result = func(**action_args)\n",
    "        if debug:\n",
    "            print(f\"action_name: {action_name}, action_args: {action_args}\")\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"调用工具异常： {e}\")\n",
    "        return str(e)\n",
    "\n",
    "def agent_execute(query, max_request_time, debug=False):\n",
    "    \"\"\"执行代理任务，与模型交互并处理结果，根据debug参数决定是否打印详细信息\"\"\"\n",
    "    cur_request_time = 0\n",
    "    chat_history = []\n",
    "    agent_scratch = \"\"\n",
    "\n",
    "    while cur_request_time < max_request_time:\n",
    "        cur_request_time += 1\n",
    "        prompt = gen_prompt(query, agent_scratch)\n",
    "        response = mp.chat(prompt, chat_history)\n",
    "\n",
    "        if not response or not isinstance(response, dict):\n",
    "            print(f\"call llm exception, response is: {response}\")\n",
    "            continue\n",
    "\n",
    "        action_info = response.get(\"action\")\n",
    "        action_name = action_info.get(\"name\")\n",
    "        action_args = action_info.get(\"args\")\n",
    "        thoughts = response.get(\"thoughts\")\n",
    "\n",
    "        if debug:\n",
    "            print(f'-------------第{cur_request_time}次推断------------')\n",
    "            print(f\"observation: {response.get('observation')}\")\n",
    "            print(f\"planning: {thoughts.get('planning')}\")\n",
    "            print(f\"reasoning: {thoughts.get('reasoning')}\")\n",
    "            print(f\"reflection: {thoughts.get('reflection')}\")\n",
    "            print(f\"summary: {thoughts.get('summary')}\")\n",
    "            print(f\"action_name: {action_name}, action_args: {action_args}\")\n",
    "\n",
    "        if action_name == \"query_user_for_details\":\n",
    "            user_response = input(query_user_for_details(action_args[\"prompt\"]))\n",
    "            chat_history.append([action_args[\"prompt\"], user_response])\n",
    "            agent_scratch += f\"query_user: {action_args['prompt']}user response: {user_response}\"\n",
    "            continue\n",
    "\n",
    "        call_function_result = execute_action(action_name, action_args, debug)\n",
    "        agent_scratch += f\"observation: {response.get('observation')} execute action {action_name} result: {call_function_result}\"\n",
    "        assistant_msg = parse_thoughts(response, cur_request_time,max_request_time,debug)\n",
    "        chat_history.append([user_prompt, assistant_msg])\n",
    "\n",
    "        if action_name == \"finish\":\n",
    "            final_answer = action_args.get(\"answer\")\n",
    "            # final_answer = \"\".join([str(key) + str(value) for key, value in final_answer.items()])\n",
    "            break\n",
    "    if cur_request_time == max_request_time:\n",
    "        final_answer=\"本次任务执行失败！,未能提供问诊建议\"\n",
    "    return final_answer\n",
    "\n",
    "# 示例执行，启用调试模式\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_request_time = 20\n",
    "query = '你好,我腱鞘炎又犯了，我应该具体吃什么药呢'\n",
    "final_answer = agent_execute(query, max_request_time=max_request_time,debug=True)\n",
    "print(f\"final_answer: {final_answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### final test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
