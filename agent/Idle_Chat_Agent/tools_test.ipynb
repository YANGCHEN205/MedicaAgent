{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"name\": \"query_user_for_details\",\n",
      "        \"description\": \"向用户提问，用于获取更多信息，以深入了解用户的需求。\",\n",
      "        \"parameters\": {\n",
      "            \"type\": \"object\",\n",
      "            \"properties\": {\n",
      "                \"query_user\": {\n",
      "                    \"type\": \"string\",\n",
      "                    \"description\": \"用户输入的信息，用于明确用户的需求。\"\n",
      "                }\n",
      "            }\n",
      "        },\n",
      "        \"required\": [\n",
      "            \"query_user\"\n",
      "        ]\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"finish\",\n",
      "        \"description\": \"结束对话并给出最终用户此轮对话的结果。\",\n",
      "        \"parameters\": {\n",
      "            \"type\": \"object\",\n",
      "            \"properties\": {\n",
      "                \"answer\": {\n",
      "                    \"type\": \"dict\",\n",
      "                    \"description\": \"最终用户此轮对话的结果。\"\n",
      "                }\n",
      "            }\n",
      "        },\n",
      "        \"required\": [\n",
      "            \"answer\"\n",
      "        ]\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"get_current_date\",\n",
      "        \"description\": \"获取当前日期并以字符串格式返回。\",\n",
      "        \"parameters\": {},\n",
      "        \"required\": []\n",
      "    }\n",
      "]\n",
      "\n",
      "1. 你有任何不清楚的信息，使用query_user_for_details向用户提问。\n",
      "2. 在调用finish之前，使用query_user_for_details向用户确认是否需要结束此次对话。\n",
      "\n",
      "\n",
      "您是一名智能闲聊助手，专门处理用户提出的各种非医学领域的问题。请根据用户的需求确定下一个要执行的动作，并尽可能基于内置的知识库提供准确且满意的回复。如果问题涉及医学，直接返回提示信息：“此问题是医学问题。需要调用其他Agent”。并使用前面指定的JSON模式进行响应：\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from ica_tools import tools_map, query_user_for_details,gen_tools_desc\n",
    "from ica_prompt import gen_prompt, user_prompt\n",
    "tools_dict= gen_tools_desc()\n",
    "print(tools_dict)\n",
    "print(user_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ica_tools import tools_map, query_user_for_details\n",
    "from ica_prompt import gen_prompt, user_prompt\n",
    "from ica_model_provider import ModelProvider\n",
    "from dotenv import load_dotenv\n",
    "import dashscope\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "mp = ModelProvider()\n",
    "\n",
    "dashscope.api_key = \"sk-f529539e3a50472fac783cf1e99fddef\"\n",
    "os.environ[\"TAVILY_API_KEY\"] = \"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\"\n",
    "\n",
    "def parse_thoughts(response, cur_request_time,max_request_time,debug):\n",
    "    \"\"\"解析模型返回的响应，提取关键信息并格式化为字符串，并根据debug参数决定是否打印\"\"\"\n",
    "    try:\n",
    "        thoughts = response.get(\"thoughts\")\n",
    "        planning = thoughts.get(\"planning\")\n",
    "        reasoning = thoughts.get(\"reasoning\")\n",
    "        reflection = thoughts.get(\"reflection\")\n",
    "        summary = thoughts.get(\"summary\")\n",
    "        observation = response.get(\"observation\")\n",
    "        prompt = f\"planning: {planning}\\nreasoning: {reasoning}\\nreflection: {reflection}\\nobservation: {observation}\\nsummary: {summary}\"\n",
    "        prompt += f\"\\n这是医疗知识库第{cur_request_time}次响应，最多执行{max_request_time}次\\n\" \n",
    "        # if debug:\n",
    "        #     print(prompt)\n",
    "        return prompt\n",
    "    except Exception as e:\n",
    "        print(f\"parse_thoughts error: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def execute_action(action_name, action_args, debug):\n",
    "    \"\"\"根据动作名称执行相应的工具函数，并根据debug参数决定是否打印动作信息\"\"\"\n",
    "    try:\n",
    "        func = tools_map.get(action_name)\n",
    "        result = func(**action_args)\n",
    "        if debug:\n",
    "            print(f\"action_name: {action_name}, action_args: {action_args}\")\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"调用工具异常： {e}\")\n",
    "        return str(e)\n",
    "\n",
    "def agent_execute(query, max_request_time, debug=False):\n",
    "    \"\"\"执行代理任务，与模型交互并处理结果，根据debug参数决定是否打印详细信息\"\"\"\n",
    "    cur_request_time = 0\n",
    "    chat_history = []\n",
    "    agent_scratch = \"\"\n",
    "\n",
    "    while cur_request_time < max_request_time:\n",
    "        cur_request_time += 1\n",
    "        prompt = gen_prompt(query, agent_scratch)\n",
    "        response = mp.chat(prompt, chat_history)\n",
    "\n",
    "        if not response or not isinstance(response, dict):\n",
    "            print(f\"call llm exception, response is: {response}\")\n",
    "            continue\n",
    "\n",
    "        action_info = response.get(\"action\")\n",
    "        action_name = action_info.get(\"name\")\n",
    "        action_args = action_info.get(\"parameters\")\n",
    "        thoughts = response.get(\"thoughts\")\n",
    "\n",
    "        if debug:\n",
    "            print(f'-------------第{cur_request_time}次推断------------')\n",
    "            print(f\"observation: {response.get('observation')}\")\n",
    "            print(f\"planning: {thoughts.get('planning')}\")\n",
    "            print(f\"reasoning: {thoughts.get('reasoning')}\")\n",
    "            print(f\"reflection: {thoughts.get('reflection')}\")\n",
    "            print(f\"summary: {thoughts.get('summary')}\")\n",
    "            print(f\"action_name: {action_name}, action_args: {action_args}\")\n",
    "\n",
    "        if action_name == \"query_user_for_details\":\n",
    "            user_response = input(query_user_for_details(action_args[\"query_user\"]))\n",
    "            chat_history.append([action_args[\"query_user\"], user_response])\n",
    "            agent_scratch += f\"query_user: {action_args['query_user']}user response: {user_response}\"\n",
    "            continue\n",
    "\n",
    "        call_function_result = execute_action(action_name, action_args, debug)\n",
    "        agent_scratch += f\"observation: {response.get('observation')} execute action {action_name} result: {call_function_result}\"\n",
    "        assistant_msg = parse_thoughts(response, cur_request_time,max_request_time,debug)\n",
    "        chat_history.append([user_prompt, assistant_msg])\n",
    "\n",
    "        if action_name == \"finish\":\n",
    "            final_answer = action_args.get(\"answer\")\n",
    "            # final_answer = \"\".join([str(key) + str(value) for key, value in final_answer.items()])\n",
    "            break\n",
    "    if cur_request_time == max_request_time:\n",
    "        final_answer=\"本次任务执行失败！,未能提供问诊建议\"\n",
    "    return final_answer\n",
    "\n",
    "# 示例执行，启用调试模式\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------第1次推断------------\n",
      "observation: 已经成功提供了用户请求的笑话，等待用户的下一步互动。\n",
      "planning: 用户请求讲个笑话，这是一个简单的闲聊需求，可以直接从知识库中选取一个笑话来回应。\n",
      "reasoning: 用户请求的是一个笑话，这是一个典型的非医学领域请求，因此可以直接从我的知识库中选择一个合适的笑话来回应，而不需要进一步的询问或确认。\n",
      "reflection: 无需改进，因为用户需求明确，且在非医学领域内。\n",
      "summary: 已提供一个笑话作为回应，满足了用户的闲聊需求。\n",
      "action_name: finish, action_args: {'answer': {'joke': '为什么袜子总是只丢一只？因为丢两只根本就不会发现。'}}\n",
      "action_name: finish, action_args: {'answer': {'joke': '为什么袜子总是只丢一只？因为丢两只根本就不会发现。'}}\n",
      "final_answer: {'joke': '为什么袜子总是只丢一只？因为丢两只根本就不会发现。'}\n"
     ]
    }
   ],
   "source": [
    "max_request_time = 10\n",
    "query = '你好,讲个笑话'\n",
    "final_answer = agent_execute(query, max_request_time=max_request_time,debug=True)\n",
    "print(f\"final_answer: {final_answer}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
